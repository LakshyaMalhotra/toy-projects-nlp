{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse matrix representation of the corpus using `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document.', \n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?'\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of words representation\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'the': 6,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'third': 7,\n",
       " 'one': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the count vectorizer with tokenizer provided by NLTK; \n",
    "# this will also take care of special characters\n",
    "vectorizer = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "\n",
    "# fit the vectorizer on the corpus\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "corpus_transformed = vectorizer.transform(corpus)\n",
    "\n",
    "corpus_transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 10,\n",
       " 'is': 5,\n",
       " 'the': 8,\n",
       " 'first': 4,\n",
       " 'document': 3,\n",
       " '.': 0,\n",
       " 'second': 7,\n",
       " 'and': 2,\n",
       " 'third': 9,\n",
       " 'one': 6,\n",
       " '?': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the same methodology on IMDB dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "df = pd.read_csv(\"../data/IMDB Dataset.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  kfold\n",
       "0  One of the other reviewers has mentioned that ...          1     -1\n",
       "1  A wonderful little production. <br /><br />The...          1     -1\n",
       "2  I thought this was a wonderful way to spend ti...          1     -1\n",
       "3  Basically there's a family where a little boy ...          0     -1\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1     -1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map positive sentiment as 1 negative as 0\n",
    "df.sentiment = df.sentiment.map({\"positive\": 1, \"negative\": 0})\n",
    "df[\"kfold\"] = -1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is a real shame that nearly no one under 30...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have read the novel Reaper of Ben Mezrich a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was very very mediocre and very ver...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay, some other people have commented that th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somewhere i'd read that this film is supposed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  kfold\n",
       "0  It is a real shame that nearly no one under 30...          0      0\n",
       "1  I have read the novel Reaper of Ben Mezrich a ...          0      0\n",
       "2  This movie was very very mediocre and very ver...          0      0\n",
       "3  Okay, some other people have commented that th...          0      0\n",
       "4  somewhere i'd read that this film is supposed ...          0      0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fetch the labels\n",
    "y = df.sentiment.values\n",
    "\n",
    "# instantiate kfold CV\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "# create stratified folds\n",
    "for idx, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "    df.loc[v_, \"kfold\"] = idx\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    10000\n",
       "3    10000\n",
       "2    10000\n",
       "1    10000\n",
       "0    10000\n",
       "Name: kfold, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "df.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Accuracy: 0.8943\n",
      "ROC AUC score: 0.9558\n",
      "Time elapsed: 311.2196 seconds.\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8941\n",
      "ROC AUC score: 0.9547\n",
      "Time elapsed: 319.5518 seconds.\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.8942\n",
      "ROC AUC score: 0.9566\n",
      "Time elapsed: 308.2627 seconds.\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8928\n",
      "ROC AUC score: 0.9559\n",
      "Time elapsed: 307.9073 seconds.\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8925\n",
      "ROC AUC score: 0.9562\n",
      "Time elapsed: 306.1910 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# go over the folds created\n",
    "for f_ in range(5):\n",
    "    # create training and validation dataframes\n",
    "    start_time = time.time()\n",
    "    train_df = df[df[\"kfold\"] != f_].reset_index(drop=True)\n",
    "    valid_df = df[df[\"kfold\"] == f_].reset_index(drop=True)\n",
    "    \n",
    "    # initialize the count vectorizer using the word_tokenize as the tokenizer\n",
    "    vectorizer = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "    \n",
    "    # fit the vectorizer on the train_df reviews\n",
    "    vectorizer.fit(train_df.review)\n",
    "    \n",
    "    # create training and validation data\n",
    "    xtrain = vectorizer.transform(train_df.review)\n",
    "    xvalid = vectorizer.transform(valid_df.review)\n",
    "    \n",
    "    # initialize logistic regression\n",
    "    model = linear_model.LogisticRegression(n_jobs=-1)\n",
    "    \n",
    "    # fit the model on training data\n",
    "    model.fit(xtrain, train_df.sentiment)\n",
    "    \n",
    "    # make predictions on validation set\n",
    "    preds = model.predict(xvalid)\n",
    "    preds_proba = model.predict_proba(xvalid)[:, 1]\n",
    "    \n",
    "    # calculate accuracy and roc score\n",
    "    accuracy = metrics.accuracy_score(valid_df.sentiment, preds)\n",
    "    roc = metrics.roc_auc_score(valid_df.sentiment, preds_proba)\n",
    "    \n",
    "    # display results\n",
    "    print(f\"Fold: {f_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC AUC score: {roc:.4f}\")\n",
    "    print(f\"Time elapsed: {(time.time() - start_time):.4f} seconds.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying some other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Accuracy: 0.8384\n",
      "Time elapsed: 296.3420 seconds.\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8350\n",
      "Time elapsed: 296.7659 seconds.\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.8516\n",
      "Time elapsed: 300.0909 seconds.\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8469\n",
      "Time elapsed: 308.1134 seconds.\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8460\n",
      "Time elapsed: 295.8493 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "# go over the folds created\n",
    "for f_ in range(5):\n",
    "    # create training and validation dataframes\n",
    "    start_time = time.time()\n",
    "    train_df = df[df[\"kfold\"] != f_].reset_index(drop=True)\n",
    "    valid_df = df[df[\"kfold\"] == f_].reset_index(drop=True)\n",
    "    \n",
    "    # initialize the count vectorizer using the word_tokenize as the tokenizer\n",
    "    vectorizer = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "    \n",
    "    # fit the vectorizer on the train_df reviews\n",
    "    vectorizer.fit(train_df.review)\n",
    "    \n",
    "    # create training and validation data\n",
    "    xtrain = vectorizer.transform(train_df.review)\n",
    "    xvalid = vectorizer.transform(valid_df.review)\n",
    "    \n",
    "    # initialize naive bayes model\n",
    "    model = naive_bayes.MultinomialNB()\n",
    "    \n",
    "    # fit the model on training data\n",
    "    model.fit(xtrain, train_df.sentiment)\n",
    "    \n",
    "    # make predictions on validation set\n",
    "    preds = model.predict(xvalid)\n",
    "    # preds_proba = model.predict_proba(xvalid)[:, 1]\n",
    "    \n",
    "    # calculate accuracy and roc score\n",
    "    accuracy = metrics.accuracy_score(valid_df.sentiment, preds)\n",
    "    # roc = metrics.roc_auc_score(valid_df.sentiment, preds_proba)\n",
    "    \n",
    "    # display results\n",
    "    print(f\"Fold: {f_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"ROC AUC score: {roc:.4f}\")\n",
    "    print(f\"Time elapsed: {(time.time() - start_time):.4f} seconds.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `tf-idf` instead of count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "\n",
    "corpus = [\n",
    "    'This is the first document.', \n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?'\n",
    "]\n",
    "\n",
    "X = tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42520648, 0.        , 0.        , 0.42520648, 0.5252146 ,\n",
       "        0.34763416, 0.        , 0.        , 0.34763416, 0.        ,\n",
       "        0.34763416],\n",
       "       [0.32513203, 0.        , 0.        , 0.65026407, 0.        ,\n",
       "        0.26581674, 0.        , 0.50938216, 0.26581674, 0.        ,\n",
       "        0.26581674],\n",
       "       [0.31055267, 0.        , 0.48654076, 0.        , 0.        ,\n",
       "        0.25389715, 0.48654076, 0.        , 0.25389715, 0.48654076,\n",
       "        0.25389715],\n",
       "       [0.        , 0.59276931, 0.        , 0.37835697, 0.46734613,\n",
       "        0.30933162, 0.        , 0.        , 0.30933162, 0.        ,\n",
       "        0.30933162]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 10,\n",
       " 'is': 5,\n",
       " 'the': 8,\n",
       " 'first': 4,\n",
       " 'document': 3,\n",
       " '.': 0,\n",
       " 'second': 7,\n",
       " 'and': 2,\n",
       " 'third': 9,\n",
       " 'one': 6,\n",
       " '?': 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 0), (0, 3), (0, 4), (0, 5), (0, 8), (0, 10), (1, 0), (1, 3), (1, 5), (1, 7), (1, 8), (1, 10), (2, 0), (2, 2), (2, 5), (2, 6), (2, 8), (2, 9), (2, 10), (3, 1), (3, 3), (3, 4), (3, 5), (3, 8), (3, 10))\n"
     ]
    }
   ],
   "source": [
    "x, y = np.where(X.toarray())\n",
    "print(tuple(zip(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Accuracy: 0.8961\n",
      "ROC AUC score: 0.9605\n",
      "Time elapsed: 307.82 seconds.\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8944\n",
      "ROC AUC score: 0.9595\n",
      "Time elapsed: 320.43 seconds.\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.8991\n",
      "ROC AUC score: 0.9613\n",
      "Time elapsed: 305.38 seconds.\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8975\n",
      "ROC AUC score: 0.9607\n",
      "Time elapsed: 308.70 seconds.\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8977\n",
      "ROC AUC score: 0.9634\n",
      "Time elapsed: 310.83 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# go over the folds created\n",
    "for f_ in range(5):\n",
    "    # create training and validation dataframes\n",
    "    start_time = time.time()\n",
    "    train_df = df[df[\"kfold\"] != f_].reset_index(drop=True)\n",
    "    valid_df = df[df[\"kfold\"] == f_].reset_index(drop=True)\n",
    "    \n",
    "    # initialize the count vectorizer using the word_tokenize as the tokenizer\n",
    "    vectorizer = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "    \n",
    "    # fit the vectorizer on the train_df reviews\n",
    "    vectorizer.fit(train_df.review)\n",
    "    \n",
    "    # create training and validation data\n",
    "    xtrain = vectorizer.transform(train_df.review)\n",
    "    xvalid = vectorizer.transform(valid_df.review)\n",
    "    \n",
    "    # initialize logistic regression\n",
    "    model = linear_model.LogisticRegression(n_jobs=-1)\n",
    "    \n",
    "    # fit the model on training data\n",
    "    model.fit(xtrain, train_df.sentiment)\n",
    "    \n",
    "    # make predictions on validation set\n",
    "    preds = model.predict(xvalid)\n",
    "    preds_proba = model.predict_proba(xvalid)[:, 1]\n",
    "    \n",
    "    # calculate accuracy and roc score\n",
    "    accuracy = metrics.accuracy_score(valid_df.sentiment, preds)\n",
    "    roc = metrics.roc_auc_score(valid_df.sentiment, preds_proba)\n",
    "    \n",
    "    # display results\n",
    "    print(f\"Fold: {f_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC AUC score: {roc:.4f}\")\n",
    "    print(f\"Time elapsed: {(time.time() - start_time):.2f} seconds.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Accuracy: 0.8982\n",
      "ROC AUC score: 0.9625\n",
      "Time elapsed: 443.80 seconds.\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8993\n",
      "ROC AUC score: 0.9617\n",
      "Time elapsed: 443.94 seconds.\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.9010\n",
      "ROC AUC score: 0.9638\n",
      "Time elapsed: 412.41 seconds.\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.9015\n",
      "ROC AUC score: 0.9629\n",
      "Time elapsed: 420.32 seconds.\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8991\n",
      "ROC AUC score: 0.9650\n",
      "Time elapsed: 443.36 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# go over the folds created\n",
    "for f_ in range(5):\n",
    "    # create training and validation dataframes\n",
    "    start_time = time.time()\n",
    "    train_df = df[df[\"kfold\"] != f_].reset_index(drop=True)\n",
    "    valid_df = df[df[\"kfold\"] == f_].reset_index(drop=True)\n",
    "    \n",
    "    # initialize the count vectorizer using the word_tokenize as the tokenizer\n",
    "    vectorizer = TfidfVectorizer(tokenizer=word_tokenize, \n",
    "                                 token_pattern=None,\n",
    "                                 ngram_range=(1, 2))\n",
    "    \n",
    "    # fit the vectorizer on the train_df reviews\n",
    "    vectorizer.fit(train_df.review)\n",
    "    \n",
    "    # create training and validation data\n",
    "    xtrain = vectorizer.transform(train_df.review)\n",
    "    xvalid = vectorizer.transform(valid_df.review)\n",
    "    \n",
    "    # initialize logistic regression\n",
    "    model = linear_model.LogisticRegression(n_jobs=-1)\n",
    "    \n",
    "    # fit the model on training data\n",
    "    model.fit(xtrain, train_df.sentiment)\n",
    "    \n",
    "    # make predictions on validation set\n",
    "    preds = model.predict(xvalid)\n",
    "    preds_proba = model.predict_proba(xvalid)[:, 1]\n",
    "    \n",
    "    # calculate accuracy and roc score\n",
    "    accuracy = metrics.accuracy_score(valid_df.sentiment, preds)\n",
    "    roc = metrics.roc_auc_score(valid_df.sentiment, preds_proba)\n",
    "    \n",
    "    # display results\n",
    "    print(f\"Fold: {f_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC AUC score: {roc:.4f}\")\n",
    "    print(f\"Time elapsed: {(time.time() - start_time):.2f} seconds.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: go\n",
      "stemed word=go\n",
      "lemmatized word=go\n",
      "\n",
      "word: goa\n",
      "stemed word=goa\n",
      "lemmatized word=goa\n",
      "\n",
      "word: gone\n",
      "stemed word=gone\n",
      "lemmatized word=gone\n",
      "\n",
      "word: going\n",
      "stemed word=go\n",
      "lemmatized word=going\n",
      "\n",
      "word: broad\n",
      "stemed word=broad\n",
      "lemmatized word=broad\n",
      "\n",
      "word: broaden\n",
      "stemed word=broaden\n",
      "lemmatized word=broaden\n",
      "\n",
      "word: broadening\n",
      "stemed word=broaden\n",
      "lemmatized word=broadening\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the lemmatizer\n",
    "\"\"\"\n",
    "Lemmatization keeps the meaning of the sentences intact.\n",
    "\"\"\"\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# initialize the stemmer\n",
    "\"\"\"\n",
    "Stemming doesn't guarantee the final word would still have some meaning.\n",
    "\"\"\"\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "words = [\"go\", \"goa\", \"gone\", \"going\", \"broad\", \"broaden\", \"broadening\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"word: {word}\")\n",
    "    print(f\"stemed word={stemmer.stem(word)}\")\n",
    "    print(f\"lemmatized word={lemma.lemmatize(word)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this was cheesy</td>\n",
       "      <td>this was cheesi</td>\n",
       "      <td>this wa cheesy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she likes these books</td>\n",
       "      <td>she like these book</td>\n",
       "      <td>she like these book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow this is great</td>\n",
       "      <td>wow this is great</td>\n",
       "      <td>wow this is great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text         text_stemmed      text_lemmatized\n",
       "0        this was cheesy      this was cheesi       this wa cheesy\n",
       "1  she likes these books  she like these book  she like these book\n",
       "2      wow this is great    wow this is great    wow this is great"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create functions to lemmatize and stem the reviews\n",
    "def lemmatize_text(text):\n",
    "    return [lemma.lemmatize(w) for w in text.split()]\n",
    "\n",
    "def stem_text(text):\n",
    "    return [stemmer.stem(w) for w in text.split()]\n",
    "\n",
    "text_df = pd.DataFrame(['this was cheesy', 'she likes these books', 'wow this is great'], columns=['text'])\n",
    "\n",
    "text_df[\"text_stemmed\"] = text_df.text.apply(stem_text).apply(lambda x: ' '.join(x))\n",
    "text_df['text_lemmatized'] = text_df.text.apply(lemmatize_text).apply(lambda x: ' '.join(x))\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to stem and lemmatize the original dataframe: 262.71 seconds.\n",
      "Fold: 0\n",
      "Accuracy: 0.8985\n",
      "ROC AUC score: 0.9617\n",
      "Time elapsed: 406.04 seconds.\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8964\n",
      "ROC AUC score: 0.9626\n",
      "Time elapsed: 423.30 seconds.\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.9053\n",
      "ROC AUC score: 0.9632\n",
      "Time elapsed: 431.30 seconds.\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8970\n",
      "ROC AUC score: 0.9611\n",
      "Time elapsed: 425.73 seconds.\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8935\n",
      "ROC AUC score: 0.9603\n",
      "Time elapsed: 405.86 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# track the time\n",
    "start = time.time()\n",
    "\n",
    "# stem the review column\n",
    "df[\"review_stemmed\"] = df.review.apply(stem_text).apply(lambda x: ' '.join(x))\n",
    "\n",
    "# lemmatize the review column\n",
    "df[\"review_lemmatized\"] = df.review.apply(lemmatize_text).apply(lambda x: ' '.join(x))\n",
    "\n",
    "print(f\"Time taken to stem and lemmatize the original dataframe: {(time.time() - start):.2f} seconds.\")\n",
    "\n",
    "# go over the folds created\n",
    "for f_ in range(5):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # create training and validation dataframe\n",
    "    train_df = df[df[\"kfold\"] != f_].reset_index(drop=True)\n",
    "    valid_df = df[df[\"kfold\"] == f_].reset_index(drop=True)\n",
    "    \n",
    "    # initialize the count vectorizer using the word_tokenize as the tokenizer\n",
    "    vectorizer = TfidfVectorizer(tokenizer=word_tokenize, \n",
    "                                 token_pattern=None,\n",
    "                                 ngram_range=(1, 2))\n",
    "    \n",
    "    # fit the vectorizer on the train_df reviews\n",
    "    vectorizer.fit(train_df.review_stemmed)\n",
    "    \n",
    "    # create training and validation data\n",
    "    xtrain = vectorizer.transform(train_df.review_stemmed)\n",
    "    xvalid = vectorizer.transform(valid_df.review_stemmed)\n",
    "    \n",
    "    # initialize logistic regression\n",
    "    model = linear_model.LogisticRegression(n_jobs=-1)\n",
    "    \n",
    "    # fit the model on training data\n",
    "    model.fit(xtrain, train_df.sentiment)\n",
    "    \n",
    "    # make predictions on validation set\n",
    "    preds = model.predict(xvalid)\n",
    "    preds_proba = model.predict_proba(xvalid)[:, 1]\n",
    "    \n",
    "    # calculate accuracy and roc score\n",
    "    accuracy = metrics.accuracy_score(valid_df.sentiment, preds)\n",
    "    roc = metrics.roc_auc_score(valid_df.sentiment, preds_proba)\n",
    "    \n",
    "    # display results\n",
    "    print(f\"Fold: {f_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC AUC score: {roc:.4f}\")\n",
    "    print(f\"Time elapsed: {(time.time() - start_time):.2f} seconds.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Accuracy: 0.8986\n",
      "ROC AUC score: 0.9623\n",
      "Time elapsed: 417.90 seconds.\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8997\n",
      "ROC AUC score: 0.9633\n",
      "Time elapsed: 423.84 seconds.\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.9035\n",
      "ROC AUC score: 0.9641\n",
      "Time elapsed: 437.06 seconds.\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8981\n",
      "ROC AUC score: 0.9625\n",
      "Time elapsed: 432.23 seconds.\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8950\n",
      "ROC AUC score: 0.9617\n",
      "Time elapsed: 438.82 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# go over the folds created\n",
    "for f_ in range(5):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # create training and validation dataframe\n",
    "    train_df = df[df[\"kfold\"] != f_].reset_index(drop=True)\n",
    "    valid_df = df[df[\"kfold\"] == f_].reset_index(drop=True)\n",
    "    \n",
    "    # initialize the count vectorizer using the word_tokenize as the tokenizer\n",
    "    vectorizer = TfidfVectorizer(tokenizer=word_tokenize, \n",
    "                                 token_pattern=None,\n",
    "                                 ngram_range=(1, 2))\n",
    "    \n",
    "    # fit the vectorizer on the train_df reviews\n",
    "    vectorizer.fit(train_df.review_lemmatized)\n",
    "    \n",
    "    # create training and validation data\n",
    "    xtrain = vectorizer.transform(train_df.review_lemmatized)\n",
    "    xvalid = vectorizer.transform(valid_df.review_lemmatized)\n",
    "    \n",
    "    # initialize logistic regression\n",
    "    model = linear_model.LogisticRegression(n_jobs=-1)\n",
    "    \n",
    "    # fit the model on training data\n",
    "    model.fit(xtrain, train_df.sentiment)\n",
    "    \n",
    "    # make predictions on validation set\n",
    "    preds = model.predict(xvalid)\n",
    "    preds_proba = model.predict_proba(xvalid)[:, 1]\n",
    "    \n",
    "    # calculate accuracy and roc score\n",
    "    accuracy = metrics.accuracy_score(valid_df.sentiment, preds)\n",
    "    roc = metrics.roc_auc_score(valid_df.sentiment, preds_proba)\n",
    "    \n",
    "    # display results\n",
    "    print(f\"Fold: {f_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC AUC score: {roc:.4f}\")\n",
    "    print(f\"Time elapsed: {(time.time() - start_time):.2f} seconds.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
